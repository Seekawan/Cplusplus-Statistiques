\documentclass{article}

% Language setting
% Replace `english' with e.g. `spanish' to change the document language
\usepackage[french]{babel}

% Set page size and margins
% Replace `letterpaper' with `a4paper' for UK/EU standard size
\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}

\title{C++ et Statistiques}
\author{Constantin Keuky}

\begin{document}
\maketitle

\begin{abstract}
Ce projet a pour objectif de coder en C++ les outils statistiques élémentaires necessaires à l'étude d'un dataset sur les performances Spotify. Une spécificité de ce projet est l'absence d'utilisation de bibliothèque pour effectuer les calculs statistiques.
\end{abstract}

\section{Description des classes}

\subsection{Forme générale}

Il existe 9 classes dans ce projet. 5 sous forme .cpp et 4 sous forme .h. La raison étant que le main n'a pas besoin de .h car il appelle les autres classes, autrement chaque classe qui n'est pas le main a son fichier .h associé.

\begin{figure}[hbt!]
\centering
\includegraphics[width=1\linewidth]{UML.png}
\caption{\label{fig:UML}Schéma UML du projet}
\end{figure}
\newpage

Il y a donc :
\begin{itemize}
    \item Artist.cpp/h, qui est notre format d'étude pour ce projet
    \item SpotifyDataset.cpp/.h, la classe qui permet l'extraction du fichier .csv
    \item StatDesc.cpp/.h, la classe qui contient les méthodes de statistiques descriptives
    \item StatInfer.cpp/.h, la classe qui contient les méthodes de statistiques inférentielles plus quelques probabilités bayésiennes
    \item main.cpp, le main pour exécuter tout ça
\end{itemize}

On compte en plus dans le dossier src le fichier .csv du dataset "Artists.csv", le fichier "main.exe" qui initialise l'application et le fichier "sauve" qui est une sauvegarde manuelle des calculs effectués.
\vspace{5mm}

\begin{tabular}{ |p{3cm}|p{2cm}|p{1.5cm}|p{2cm}|p{2cm}|p{2cm}|  }
 \hline
 \multicolumn{6}{|c|}{Extrait de artists.csv} \\
 \hline
 Artist&Streams&Daily&As lead&Solo&As feature\\
 \hline
Billie Eilish&"29,173.3"&19.313&"29,173.3"&"25,240.5"&NULL\\
XXXTENTACION&"28,370.7"&11.181&"24,681.3"&"20,244.5"&"3,689.4"\\
Chris Brown&"28,314.1"&12.788&"14,904.7"&"7,064.1"&"13,409.3"\\
Imagine Dragons&"28,100.5"&16.133&"26,430.9"&"22,543.8"&"1,669.6"\\
Khalid&"27,776.0"&8.833&"14,779.4"&"9,759.3"&"12,996.6"\\
 \hline
\end{tabular}
\vspace{5mm}

\subsection{Artist}
\subsubsection{.h}
"pragma once", pour éviter les multi inclusions sachant que cette classe va être la plus utilisée
"include <string>", pour avoir accès aux chaines de caractère
\\Dans le "private:" : la déclaration de tous les attributs qui sont ceux que l'on retrouve dans le fichier .csv
\\Dans le "public:" : en premier la déclaration de la méthode constructeur qui a tous les paramètres, puis les getters

\subsubsection{.cpp}
"include "Artist.h"", son fichier header dont il va définir le contenu des méthodes déclarées.
\\Le contenu des méthodes précédentes, majoritairement de la lecture de données

\subsection{SpotifyDataset}
\subsubsection{.h}
"include "Artist.h"", pour utiliser les méthodes de Artist qui sont necessaires à l'extraction ordonnée du fichier csv
\\"include <vector>", pour utiliser les vecteurs, ce choix permet de simplifier le developpement les arrays étant un peu plus complexe à manipuler
\\Dans le "private" : 
\begin{itemize}
\item trim, normalizeKey et parseCSVLine qui sont des méthodes helpers pour le travail d'extraction
\item ColMap, une structure qui reprend la forme attendue de nos données propres
\item builColumnMap qui définit le nom des colonnes à partir de la première ligne
\item parseNumber, transforme les données du csv en type double
\end{itemize}
Dans le "public" :  
\begin{itemize}
\item loadFromCSV qui extrait les valeurs du fichiers
\item getArtists qui convertit les données sous format artiste
\item getAttribute qui est un getter pour les propriétés des artistes
\end{itemize}

\subsubsection{.cpp} 
"include "SpotifyDataset.h"", son fichier header dont il va définir le contenu des méthodes déclarées
\\"include <fstream>", bibliothèque pour manipuler les fichiers .txt
\\"include <sstream>", pour plus facilement manipuler les string
\\"include <cctype>", pour avoir accès à des méthodes de manipulation des caractères individuels
\\Le contenu des méthodes précédentes, majoritairement de l'extraction et formatage de données

\subsection{StatDesc}
\subsubsection{.h}
"include "Artist.h"", car c'est notre format de travail
\\Dans le "public" : 
\begin{itemize}
    \item mean qui fait la moyenne
    \item median qui trouve la médianne
    \item mode qui trouve la valeur mode du dataset
    \item min et max pour les valeurs minimales et maximales
    \item variance qui fait la variance d'une variable
    \item stddev pour standart deviation-l'écart type
    \item topN qui donne les premiers N max d'un attribut
    \item topGapLead qui donne l'écart max au sein d'une variable
    \item printSoloFeatureRatio qui fait la comparaison entre les apparitions solo ou feat des artistes
    \item printGlobalSoloFeatureRatio qui fait ce calcul pour tous les artistes
\end{itemize}

\subsubsection{.cpp}
"include <map>", pour pouvoir utiliser les clefs
\\"include <cmath>", qui donne accès à quelques fonctions mathématiques de référence comme exp-log-sin... Ne donne pas accès à des méthodes explicites de calcul statistique
\\Le contenu des méthodes précédentes, majoritairement des statistiques descriptives

\subsection{StatInfer}
\subsubsection{.h}
"include "Artist.h"", car c'est notre format de travail
\\Dans le "public" : 
\begin{itemize}
    \item probaTopN la probabilité de tirer au hasard un artiste faisant partie du top n configurable selon les streams
    \item probaParSoloRatio la probabilité qu’un artiste ait plus de n\%, aussi configurable, de ses streams en solo
    \item probaCondTopNdailygivenhighStreams la proba d’être top n configurable daily si streams \> seuilStreams
    \item intervalleConfianceMoyenne qui fait l'IC 95\% sur la moyenne
    \item intervalleConfianceProportion qui fait l'IC sur une proportion par demi-largeur
    \item ttest2moyennes le test de student sur 2 moyennes
    \item testProportion via z-test
    \item regressionLineaire de forme simple aX + b
    \item pearson qui calcule le coefficient éponyme
    \item regressionAsciiPlot qui affiche graphiquement le résultat de la regression linéaire
\end{itemize}

\subsubsection{.cpp}
"include <cmath>", qui donne accès à quelques fonctions mathématiques de référence comme exp-log-sin... Ne donne pas accès à des méthodes explicites de calcul statistique
\\Le contenu des méthodes précédentes, majoritairement des statistiques inférentielles

\subsection{Main}

"include "SpotifyDataset.h"", appel de la classe d'extraction, par ailleurs pas besoin de rappeler la classe Artist étant déjà appelée dans cette classe
\\"include "StatDesc.h"", appel de la classe de statistiques descriptives
\\"include "StatInfer.h"", appel de la classe de statistiques inférentielles
\\define COLORGREEN   "033[1;32m" define COLORRESET  "033[0m" define COLORBOLD   "033[1m", pour mettre la console en vert IBM.
\\lastResult, qui sert a stocker les lignes pour la sauvegarde, il est d'accessibilité globale.
\\Et les méthodes :
\begin{itemize}
    \item handleXCommand, ce sont des méthodes qui permettent de simplifier l'appel des méthodes de calcul statistique dans le main. Toutes les méthodes ne sont pas sous ce format, certaine sont explicitement appelées et configurées directement dans le main. Les méthodes handleXCommand existent surtout par soucis de clarté
    \item split et saveToFile qui permettent la segmentation et la sauvegarde des résultats dans un fichier distinct
    \item showMenu qui donne un affichage complet des commandes disponibles avec exemples
    \item main qui appelle toutes les méthodes précédentes il est bouclé pour une exécution continue sauf si on le quitte
\end{itemize}

\section{Traitement du CSV}

\subsection{Spécifications}
Les classes SpotifyDataset chargent un fichier CSV d’artistes Spotify, nettoient et convertissent les champs, puis construisent un objet Artist par ligne valide. Elles ont les caractéristiques suivantes :

\begin{itemize}
    \item respecter le format CSV standard (RFC 4180) : guillemets, virgules internes, guillemets échappés
    \item tolérer des variations d’en-têtes (ordre et alias de colonnes)
    \item gérer des conventions numériques courantes (séparateurs de milliers, virgule décimale)
    \item rester résilient : une ligne invalide n’interrompt pas l’import; un bilan est journalisé
\end{itemize}
\vspace{2mm}
Le format attendu est de 6 colonnes :
\begin{enumerate}
    \item Artist (texte)
    \item Streams (numérique)
    \item Daily (numérique)
    \item As lead (numérique)
    \item Solo (numérique)
    \item As feature (numérique)
\end{enumerate}
Ces colonnes peuvent être réordonnées et renommées si la première ligne est un en‑tête car elles y sont dérivées.

\subsection{Méthodes}
\subsubsection{API externe}
Les méthodes suivantes sont accessibles par toutes les classes qui font appel à SpotifyDataset.cpp :\\
\begin{itemize}
    \item bool loadFromCSV(const std::string\& filename) Lit et parse le fichier, remplit un std::vector<Artist>. Retourne false si le fichier ne peut pas être ouvert; true sinon (même si des lignes sont ignorées).
    \item const std::vector<Artist>\& getArtists() const Renvoie la liste des artistes importés.
    \item std::vector<double> getAttribute(const std::string\& attr) const Extrait un vecteur numérique pour un attribut (streams, daily, solo, aslead/as\_lead, asfeature/as\_feature).
\end{itemize}
    
\subsubsection{API interne}
\begin{itemize}
    \item parseCSVLine: découpe une ligne en champs, compatible RFC 4180 (guillemets, virgules internes, guillemets échappés).
    \item buildColumnMap: détecte la présence d’un en‑tête et mappe les libellés vers les indices de colonnes.
    \item parseNumber: conversion texte → double avec gestion des groupements et de la virgule décimale.
    \item trim / normalizeKey: utilitaires de nettoyage et de normalisation.
\end{itemize}

\subsection{Pipeline de traitement}

\subsubsection{Ouverture du fichier}

Ouverture via std::ifstream.
\\Si échec: loadFromCSV renvoie false (aucune donnée chargée).

\subsubsection{Première ligne: en‑tête ou données ?}

    La première ligne est lue et découpée via parseCSVLine.
    Heuristique d’en‑tête avec buildColumnMap: si au moins 3 libellés reconnus (artist/streams/etc.), la ligne est traitée comme un en‑tête.
    Deux cas: 
    \begin{itemize}
        \item En‑tête reconnu: on retient un mapping colonne→indice basé sur les libellés.
        \item Pas d’en‑tête: mappage positionnel fixe (0..5) et la première ligne est traitée comme des données (pas de perte de la première data row).
    \end{itemize}

\subsubsection{Lecture des lignes suivantes}
Pour chaque ligne:
\begin{enumerate}
    \item Découpage robuste via parseCSVLine (gère guillemets, virgules internes, guillemets échappés).
    \item Filtrage des lignes vides.
    \item Validation simple du nombre de colonnes.
    \item Conversion des champs numériques via parseNumber.
    \item Si toutes les conversions réussissent: construction de Artist(name, streams, daily, asLead, solo, asFeature) et insertion dans le vecteur.
    \item En cas d’erreur (conversion impossible, nom vide, etc.): la ligne est ignorée; un message explicite est journalisé sur std::cerr.
\end{enumerate}
    


\subsection{Détails sur le Parsing CSV (RFC 4180)}

\subsubsection{Gestion des guillemets}

    Les champs peuvent être entourés de guillemets pour contenir des virgules littérales.
    \\Les guillemets internes sont échappés en les doublant: "" représente ".
    \\parseCSVLine parcourt la ligne caractère par caractère avec un état inQuotes:
    \begin{itemize}
        \item " inverse l’état, sauf si c’est un guillemet échappé ("" → ajoute un " au champ).
        \item une virgule hors guillemets sépare les champs.
        \item   fin de ligne → on pousse le champ courant.
    \end{itemize}
    Chaque champ est nettoyé (trim) en entrée et en sortie de parseCSVLine.

\subsubsection{Exemples de découpage}

    Entrée: Taylor Swift,"85,041.3",412.6,"70,000",60000,25041.3 \\Sortie: ["Taylor Swift", "85,041.3", "412.6", "70,000", "60000", "25041.3"]
    \\Entrée: "AC/DC","He said ""Hello""" \\Sortie: ["AC/DC", "He said "Hello""]

\subsubsection{Détection d’en‑tête et mapping des colonnes}

    normalizeKey supprime espaces/underscores/tirets et met en minuscules; \\ex.: "As lead", as\_lead, AS-LEAD → aslead.
    \\buildColumnMap reconnaît notamment:
    \begin{itemize}
        \item artist, name → nom d’artiste
        \item streams, stream → total de streams
        \item daily → métrique journalière
        \item aslead, lead, asprincipal → streams en lead
        \item solo → streams solo
        \item asfeature, feature, feat → streams en feature
    \end{itemize}
    Si la première ligne est un en‑tête (plus de 3 noms reconnus), on utilise ce mapping. \\Sinon, on utilise le mapping positionnel 0..5 et on traite la ligne 1 comme des données.

\subsubsection{Étapes de parseNumber:}

    Trim du champ.
    \\Chaîne vide → retourne 0.0 (politique par défaut; peut être changée pour « vide = erreur »).
    \\Suppression des espaces internes typiques de groupement ("60 000" → "60000").
    \\Gestion virgule/point:
        \\s’il y a des virgules et pas de point:
            \\si une seule virgule: interprétée comme virgule décimale ("85,3" → "85.3");
            \\si plusieurs virgules: considérées comme séparateurs de milliers (toutes supprimées: "85,041,300" → "85041300").
        \\s’il y a virgules et point: les virgules sont des séparateurs de milliers (supprimées).
        \\sinon: entier « pur ».
    \\Conversion par std::stod (accepte +/-, notation exponentielle, etc.).
    \\Si des caractères traînants subsistent après la conversion, un avertissement est émis.
    \\En cas d’échec: message d’erreur contextualisé et exception relancée (la ligne sera ignorée par le code appelant).

\subsubsection{Exemples de conversion}

    "85,041.3" → 85041.3 (milliers + point décimal)
    \\"85,3" → 85.3 (virgule décimale)
    \\"60 000" → 60000
    \\"" → 0.0 (champ vide)

\subsubsection{Remarque sur l’ambiguïté du style “1,234”}
Le choix par défaut est “une seule virgule sans point = virgule décimale” (1,234 → 1.234). Si à la place on a la virgule comme séparateur de milliers (1,234 → 1234), il est possible d’ajuster ce comportement.

\subsection{Gestion des erreurs et résilience}

    Granularité: l’erreur sur un champ d’une ligne fait ignorer la ligne entière, mais l’import continue.
    \\Journalisation: erreurs/avertissements sur std::cerr avec numéro de ligne et valeur incriminée.
    \\Bilan final: message “X ligne(s) importée(s), Y ignorée(s). Total artistes: Z”.
    \\Sémantique de retour: loadFromCSV renvoie true si le fichier s’ouvre, même si certaines lignes sont ignorées.
    \\Idempotence: artists.clear() est appelé en début de loadFromCSV pour remplacer un import précédent.

\subsection{Complexité et performance}

    Temps: linéaire dans la taille du fichier. parseCSVLine et std::stod dominent le coût.
    Mémoire: un Artist par ligne valide; pas de préallocation (possible d’ajouter reserve si on connaît la taille).

\subsection{Cas limites}

    Retours à la ligne à l’intérieur d’un champ guillemeté: non supportés (nécessiterait un lecteur multi‑lignes).
    \\Unicode/locale: la normalisation des en‑têtes repose sur isalnum/isspace de la locale C; des en‑têtes très exotiques peuvent ne pas être reconnus.
    \\Ambiguïté virgule décimale vs séparateur de milliers: la règle choisie fonctionne avec notre modèle mais n'est pas universel.

\subsection{Exemples d'extraction de ligne}

    Cas 1 — guillemets + virgules internes Taylor Swift,"85,041.3",412.6,"70,000",60000,25041.3 → découpage correct; conversions 85,041.3 → 85041.3, "70,000" → 70000; ligne importée.
    \\Cas 2 — décimale européenne Amelie,"85,3",410,70000,60000,25341 → "85,3" → 85.3; ligne importée.
    \\Cas 3 — champ numérique vide Unknown Artist,"",0,"","","" → champs vides → 0.0; ligne importée (politique par défaut).


\subsection{Améliorations possibles}

    Rapport d’import structuré: ajouter une surcharge loadFromCSV(..., LoadReport\&) pour retrouver dans le code le nombre exact de lignes importées/ignorées et les détails d’erreurs.
    \\Gestion du cas “valeur vide”: rendre configurable le choix “vide = 0.0” vs “vide = erreur”.
    \\Choix virgule décimale vs milliers: rendre cette règle configurable au niveau du dataset.
    \\Préallocation de mémoire: si les volumes sont grands et la taille connue.


\section{Méthodes de calcul}

\section{Analyse des résultats}

\end{document}